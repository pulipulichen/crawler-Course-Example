# crawler-Course-Example: 自動排程網路爬蟲教材

A fully automated solution for web scraping. It includes automatic scheduling and triggering through GitHub Actions, data collection using Node.js's Puppeteer, and data preservation on GitHub Pages for use by others.

一套網路爬蟲的全自動解決方案。包含了透過GitHub Action自動排程啟動、使用Node.js的Puppet蒐集資料、以GitHub Pages保存資料供其他人使用。

![](https://blogger.googleusercontent.com/img/a/AVvXsEiymaRroiyKWA-PmXVDoBS-U7UNNhz-CIqeerjUBvdIxunZ_Zvz-g0brQBiDvG-NNIjVVDF6ohOK1spJ9r0ipdu7Un_37wsorFkYL1hNWui9AXk-jLYlho1CB08TQ6F-lh2qHNAw3QI6tVu7nzKPB_kOchre9C3M70xCcWybx4k6zD6_yWQn0AQzw)

## Technoligies

- **Node.js**
- **GitHub Action**: 自動排程執行的DevOps方案。
- **Puppeteer**: Node.js的瀏覽器模擬工具。

## Slide

- [網路爬蟲實作 - 112-1 資訊儲存與檢索](https://docs.google.com/presentation/d/1z5dZUTdesub-muPJ7dMhar9f7d4hIr9OySLaylacYYU/edit?usp=sharing)

----

# Memo

最後記得用以下欄位儲存：

- id: 一定要有id。
- dc.title
- dc.creator
- dc.subject
- dc.description
- dc.publisher
- dc.contributor
- dc.date: 建議轉換成ISO格式。
- dc.type
- dc.format
- dc.identifier
- dc.source
- dc.language
- dc.relation
- dc.coverage
- dc.rights

# API

https://pulipulichen.github.io/crawler-Course-Example/data.csv
